import streamlit as st
import google.generativeai as genai

# C·∫§U H√åNH TRANG WEB
st.set_page_config(page_title="App AI C·ªßa T√¥i")
st.title("ü§ñ Chat v·ªõi AI")

# B√ç K√çP C·ª¶A B·∫†N (D√°n n·ªôi dung v√†o gi·ªØa 2 d·∫•u ngo·∫∑c k√©p b√™n d∆∞·ªõi)
# L∆∞u √Ω: Kh√¥ng x√≥a 3 d·∫•u ngo·∫∑c k√©p ·ªü ƒë·∫ßu v√† cu·ªëi!
my_instruction = """
T√¥i mu·ªën t·∫°o m·ªôt App v·ªÅ Prompt Generator. T√¥i s·∫Ω ƒë∆∞a cho b·∫°n √Ω t∆∞·ªüng, v√†i √Ω ki·∫øn, b·∫°n s·∫Ω gi√∫p t√¥i vi·∫øt t·∫°o ra m·ªôt prompt chu·∫©n chuy√™n nghi·ªáp nh∆∞ m·ªôt chuy√™n gia vi·∫øt prompt v·ªõi 20 nƒÉm kinh nghi·ªám, d√πng t·∫°o ·∫£nh, t·∫°o video, t·∫°o b√†i bi·∫øt... Giao di·ªán hi·ªán ƒë·∫°i, phong c√°ch t∆∞∆°ng tai.
Gemini 3 Flash Preview
Ran for 9s
lightbulb
Thought for 9 seconds
metadata.json
check_circle
index.html
check_circle
index.tsx
check_circle
types.ts
check_circle
constants.tsx
check_circle
geminiService.ts
check_circle
App.tsx
check_circle
User
Th√™m n√∫t ƒë·ªÉ t·∫°o ra ·∫£nh, video, b√†i vi·∫øt v√† v·ª´a t·∫°o ra prompt ƒë√≥. Click on ƒë·ªÉ view large on new tap, v√† c√≥ n√∫t ƒë·ªÉ t·∫£i ·∫£nh, video, b√†i vi·∫øt ƒë√≥ xu·ªëng
Gemini 3 Flash Preview
Ran for 142s
lightbulb
Thought for 7 seconds
I will now update the application to include direct generation capabilities for images, videos, and articles, along with the professional prompt generation.
Specification of Updates:
AI Integration:
Images: Integrated gemini-2.5-flash-image to generate visual assets based on the engineered prompt.
Videos: Integrated veo-3.1-fast-generate-preview for high-quality video generation (including mandatory API key selection check for Veo models).
Articles: Enhanced text generation for full-length content.
User Interface Enhancements:
Added an "Execute Construction" button that performs both prompt engineering and asset generation in one workflow.
Created a Preview Gallery to showcase the generated image or video.
Implemented "View Fullscreen" for images/videos and "Download Asset" buttons.
Added a Progress System for video generation with reassuring status messages (since video takes longer).
Functionality:
Automatic triggering of the openSelectKey() dialog for video generation if a key hasn't been selected.
Safe handling of base64 data for downloads.
Direct link to billing documentation as required by the Veo guidelines.
Implementation:
geminiService.ts
check_circle
App.tsx
check_circle
Analyzed errors for 79 seconds
lightbulb
Thought for 76 seconds
App.tsx
check_circle
geminiService.ts
check_circle
User
t·∫°o m·ªôt n√∫t ri√™ng ƒë·ªÉ cho generator h√¨nh, video, b√†i vi·∫øt, v√† n√∫t ri√™ng ƒë·ªÉ t·∫°o prompt
Gemini 3 Flash Preview
Ran for 33s
lightbulb
Thought for 5 seconds
App.tsx
check_circle
User
ch·ªânh l·∫°i, h√¨nh kh√¥ng c√≥ xu·∫•t hi·ªán ·ªü tap m·ªõi, khi b·∫•m v√†o
Gemini 3 Flash Preview
Ran for 31s
lightbulb
Thought for 24 seconds
ƒê·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ h√¨nh ·∫£nh kh√¥ng hi·ªÉn th·ªã khi m·ªü tab m·ªõi (th∆∞·ªùng do tr√¨nh duy·ªát ch·∫∑n m·ªü tr·ª±c ti·∫øp URL Base64 dung l∆∞·ª£ng l·ªõn), t√¥i s·∫Ω c·∫≠p nh·∫≠t logic ƒë·ªÉ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu h√¨nh ·∫£nh sang Blob URL. ƒê·ªìng th·ªùi, t√¥i s·∫Ω tinh ch·ªânh giao di·ªán ƒë·ªÉ t√°ch bi·ªát r√µ r√†ng hai n√∫t: Engineer Prompt (X√¢y d·ª±ng k·ªãch b·∫£n) v√† Asset Synthesis (T·∫°o s·∫£n ph·∫©m cu·ªëi).
C√°c thay ƒë·ªïi ch√≠nh:
Logic H√¨nh ·∫£nh: Trong geminiService.ts, h√†m generateImage gi·ªù ƒë√¢y s·∫Ω tr·∫£ v·ªÅ m·ªôt Object URL thay v√¨ chu·ªói Base64. ƒêi·ªÅu n√†y gi√∫p tr√¨nh duy·ªát x·ª≠ l√Ω vi·ªác hi·ªÉn th·ªã ·ªü tab m·ªõi v√† t·∫£i xu·ªëng ·ªïn ƒë·ªãnh h∆°n.
Giao di·ªán N√∫t b·∫•m: T√°ch bi·ªát ho√†n to√†n hai kh·ªëi ch·ª©c nƒÉng. Ng∆∞·ªùi d√πng c√≥ th·ªÉ ch·ªçn ch·ªâ t·∫°o Prompt ƒë·ªÉ tinh ch·ªânh th·ªß c√¥ng, ho·∫∑c nh·∫•n n√∫t T·∫°o ƒë·ªÉ AI th·ª±c hi·ªán s·∫£n ph·∫©m (·∫¢nh/Video/B√†i vi·∫øt) d·ª±a tr√™n Prompt ƒë√£ c√≥ ho·∫∑c √Ω t∆∞·ªüng g·ªëc.
T√≠nh nƒÉng Xem/T·∫£i: ƒê·∫£m b·∫£o n√∫t "M·ªü to√†n m√†n h√¨nh" ho·∫°t ƒë·ªông m∆∞·ª£t m√† cho c·∫£ ·∫¢nh v√† Video b·∫±ng c√°ch s·ª≠ d·ª•ng Blob.
geminiService.ts
check_circle
App.tsx
check_circle
User
th√™m m·ªôt ph·∫ßn ƒë·ªÉ t√¥i t·∫£i ·∫£nh l√™n, sau ƒë√≥ b·∫°n s·∫Ω ph√¢n t√≠ch t·∫•m h√¨nh ƒë√≥ v√† generate ra prompt
Gemini 3 Flash Preview
Ran for 17s
lightbulb
Thought for 9 seconds
T√¥i s·∫Ω n√¢ng c·∫•p h·ªá th·ªëng ƒë·ªÉ t√≠ch h·ª£p th√™m b·ªô gi·∫£i m√£ h√¨nh ·∫£nh (Visual Decoder). B·∫°n c√≥ th·ªÉ t·∫£i ·∫£nh l√™n, AI s·∫Ω ph√¢n t√≠ch m·ªçi chi ti·∫øt t·ª´ phong c√°ch, √°nh s√°ng ƒë·∫øn b·ªë c·ª•c ƒë·ªÉ t·∫°o ra m·ªôt b·∫£n thi·∫øt k·∫ø (Prompt) chuy√™n nghi·ªáp nh·∫•t.
C√°c c·∫≠p nh·∫≠t ch√≠nh:
H·ªá th·ªëng t·∫£i t·ªáp: Th√™m khu v·ª±c k√©o th·∫£ ho·∫∑c ch·ªçn ·∫£nh v·ªõi hi·ªáu ·ª©ng radar qu√©t ƒë·∫∑c tr∆∞ng c·ªßa t∆∞∆°ng lai.
Visual Intelligence: S·ª≠ d·ª•ng model gemini-3-flash-preview ƒë·ªÉ ph√¢n t√≠ch ·∫£nh ƒë·∫ßu v√†o v√† chuy·ªÉn ƒë·ªïi th√†nh m√¥ t·∫£ k·ªπ thu·∫≠t cao.
B·ªë c·ª•c giao di·ªán: Khu v·ª±c t·∫£i ·∫£nh ƒë∆∞·ª£c ƒë·∫∑t ngay tr√™n ph·∫ßn nh·∫≠p li·ªáu vƒÉn b·∫£n, cho ph√©p b·∫°n k·∫øt h·ª£p c·∫£ ·∫£nh v√† m√¥ t·∫£ ƒë·ªÉ t·∫°o ra Prompt t·ªëi ∆∞u nh·∫•t.
geminiService.ts
check_circle
App.tsx
check_circle
User
Please implement the following improvements to the app based on previous feedback:
Standardize output prompt format: Ensure that all generated prompts follow a consistent schema with clearly labeled sections in this order: [SUBJECT], [STYLE], [LIGHTING], [COMPOSITION], [CAMERA / RENDER], [MOOD], [NEGATIVE PROMPT], [ASPECT RATIO / QUALITY]. The generated prompt should always include these sections, even if some are empty, to provide predictable structure for users and compatibility with Midjourney/Veo/Sora.
Enhance Visual Decoder: When analyzing an uploaded image, separate the output into two distinct categories: (a) Observed description (what the image visibly shows) and (b) Inferred details (likely style, lens/camera, estimated lighting setup). Include fields such as "INFERRED STYLE", "LIKELY CAMERA", and "ESTIMATED LIGHT SETUP". Also add a toggle allowing the user to choose between "Literal analysis" (strictly based on visible details) and "Creative reconstruction" (allows AI to creatively infer style and composition beyond what's visible). The default should be Literal analysis.
Restructure the UI into a three-step wizard:
Step 1 ‚Äì Input: User enters text and optionally uploads an image. Provide clear fields for each input and hints where appropriate.
Step 2 ‚Äì Engineer Prompt: Display the engineered prompt in the standardized format from step 1. Allow the user to edit or copy the prompt here.
Step 3 ‚Äì Generate Asset: User chooses to generate an image, video, or article using the engineered prompt. Separate this final generation step from the prompt engineering.
Input validation and hints: Add validation to check if the input text is too short (e.g., fewer than a few keywords) and warn users. If a video mode is selected but the prompt lacks motion-related keywords, automatically add a default camera movement suggestion and inform the user. If an image is uploaded without selecting a template, provide a hint to choose an appropriate template.
System Template presets and locking: Make system templates read-only and provide preset descriptions (e.g., "Midjourney Expert ‚Äì hyper-realistic, cinematic, print-ready", "Visual Narrative ‚Äì complex camera angles, visual storytelling", etc.). Users should select from presets but not modify the core template text.
Prompt history: Keep a local history of the 10‚Äì20 most recent prompts generated (can be stored in localStorage). Provide a simple list or dropdown where users can select a previous prompt to reload it.
Please update the codebase to incorporate these improvements, maintaining the existing functionality while enhancing the user experience for both novice and advanced users.
Gemini 3 Flash Preview
Ran for 7s
lightbulb
Thought for 7 seconds
types.ts
check_circle
geminiService.ts
check_circle
App.tsx
check_circle
constants.tsx
check_circle
User
Please modify the app so that after an asset (e.g., an image) has been generated in Step 3, the user can still return to Step 1 and edit the raw idea text. Do not disable the raw idea input after generation; allow users to revise their initial idea and regenerate a new prompt and asset as needed. The UI should keep the original input accessible and editable even after a generation cycle.
Gemini 3 Flash Preview
Ran for 45s
lightbulb
Thought for 13 seconds
App.tsx
check_circle
lightbulb_tips
Suggestions
"""

# NH·∫¨P KH√ìA API
api_key = st.text_input("D√°n m√£ API Key c·ªßa b·∫°n v√†o ƒë√¢y:", type="password")

if api_key:
    try:
        # K·∫æT N·ªêI GOOGLE
        genai.configure(api_key=api_key)
        
        # T·∫†O AI V·ªöI B√ç K√çP
        model = genai.GenerativeModel(
            'gemini-1.5-flash',
            system_instruction=my_instruction
        )

        # KHUNG CHAT
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        # Hi·ªán tin nh·∫Øn c≈©
        for role, text in st.session_state.chat_history:
            st.chat_message(role).write(text)

        # Nh·∫≠p tin nh·∫Øn m·ªõi
        if prompt := st.chat_input("H·ªèi g√¨ ƒëi b·∫°n..."):
            st.chat_message("user").write(prompt)
            st.session_state.chat_history.append(("user", prompt))
            
            # AI Tr·∫£ l·ªùi
            response = model.generate_content(prompt)
            st.chat_message("ai").write(response.text)
            st.session_state.chat_history.append(("ai", response.text))

    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra: {e}")
